{
  "fixture_id": "hybrid-decision-bakeoff-v1",
  "version": "1.0.0",
  "description": "Reusable bakeoff fixture for comparing decision workflows with fixed scenarios and a fixed judge rubric.",
  "current_platform": "chatgpt",
  "major_platforms": ["chatgpt", "claude", "gemini", "copilot"],
  "options_under_test": [
    {
      "id": "skill-reviewer",
      "label": "Skill Reviewer only",
      "mode": "skill-reviewer-only",
      "skill_paths": ["skills/skill-reviewer/SKILL.md"]
    },
    {
      "id": "comparative-analysis",
      "label": "Comparative Analysis only",
      "mode": "comparative-analysis-only",
      "skill_paths": ["skills/comparative-analysis/SKILL.md"]
    },
    {
      "id": "compose-both",
      "label": "Compose both workflows",
      "mode": "compose-both",
      "skill_paths": ["skills/skill-reviewer/SKILL.md", "skills/comparative-analysis/SKILL.md"]
    }
  ],
  "output_contract": {
    "max_words": 300,
    "required_sections": [
      "criteria with weights",
      "ranked alternatives with numeric scores",
      "recommended action label (select/improve/extend/compose/build-new)",
      "concise decision record snippet"
    ],
    "single_response": true,
    "criteria_confirmation_policy": "If confirmation is normally required, state assumptions and proceed in one-shot."
  },
  "judge_rubric": {
    "scale": "0-100 total",
    "criteria": [
      {
        "id": "output-spec-compliance",
        "name": "Output spec compliance",
        "weight": 25
      },
      {
        "id": "constraint-adherence",
        "name": "Constraint adherence",
        "weight": 25
      },
      {
        "id": "internal-consistency-rigor",
        "name": "Internal consistency and rigor",
        "weight": 25
      },
      {
        "id": "evidence-gap-handling",
        "name": "Evidence-gap handling",
        "weight": 15
      },
      {
        "id": "actionability",
        "name": "Actionability",
        "weight": 10
      }
    ]
  },
  "aggregation_rules": {
    "scenario_score": "weighted sum of judge rubric criteria",
    "option_score": "mean of scenario totals",
    "ranking": ["avg_total desc", "stdev asc", "option id asc"],
    "expected_run_count": 9
  },
  "scenarios": [
    {
      "id": "S1-WorkflowSelection",
      "title": "Choose workflow for comparing two local skill definitions",
      "decision_statement": "Choose the best workflow for comparing two local skill definitions.",
      "alternatives": [
        {
          "id": "A",
          "name": "Skill Reviewer Workflow",
          "pros": ["strongest skill-specific rubric depth", "SCAR structure"],
          "cons": ["no built-in scoring script", "higher interaction overhead"]
        },
        {
          "id": "B",
          "name": "Comparative Analysis Workflow",
          "pros": ["deterministic scoring script and tie-break rules", "broader applicability"],
          "cons": ["less specialized skill-review nuance"]
        },
        {
          "id": "C",
          "name": "Composed Workflow (A+B)",
          "pros": ["highest rigor", "high decision record quality"],
          "cons": ["highest setup and coordination overhead"]
        }
      ],
      "constraints": [
        "one engineer",
        "60 minutes",
        "single response (no follow-up)",
        "objective ranking required"
      ]
    },
    {
      "id": "S2-CrossPlatformTooling",
      "title": "Choose adoption strategy for policy-compliance evaluator",
      "decision_statement": "Choose an adoption strategy for an internal policy-compliance evaluator.",
      "alternatives": [
        {
          "id": "A",
          "name": "Existing Checker",
          "facts": {
            "setup_hours": 2,
            "score_consistency_100": 60,
            "platforms": ["chatgpt"],
            "maintenance_hours_per_month": 1
          }
        },
        {
          "id": "B",
          "name": "Deterministic Evaluator Script",
          "facts": {
            "setup_hours": 6,
            "score_consistency_100": 88,
            "platforms": ["chatgpt", "claude", "gemini", "copilot"],
            "maintenance_hours_per_month": 3
          }
        },
        {
          "id": "C",
          "name": "Hybrid LLM-Judge + Deterministic Script",
          "facts": {
            "setup_hours": 10,
            "score_consistency_100": 93,
            "platforms": ["chatgpt", "claude", "gemini", "copilot"],
            "maintenance_hours_per_month": 6
          }
        }
      ],
      "constraints": [
        "pilot this week",
        "maintenance budget <= 4h/month",
        "must support at least 3 major platforms",
        "single response"
      ]
    },
    {
      "id": "S3-UrgentIncident",
      "title": "Choose PR feedback triage approach during active incident",
      "decision_statement": "Choose a PR feedback triage approach during an active incident.",
      "alternatives": [
        {
          "id": "A",
          "name": "Manual triage",
          "facts": {
            "setup_minutes": 0,
            "throughput_comments_per_hour": 10,
            "safety_confidence": "highest known behavior",
            "automation_level": "low"
          }
        },
        {
          "id": "B",
          "name": "handle-pr-feedback automation",
          "facts": {
            "setup_minutes": 30,
            "throughput_comments_per_hour": 40,
            "evidence_gaps": ["edge-case safety"]
          }
        },
        {
          "id": "C",
          "name": "Compose handle-pr-feedback + resolve-pr-comments",
          "facts": {
            "setup_minutes": 75,
            "throughput_comments_per_hour": 55,
            "evidence_gaps": ["rollback behavior"],
            "complexity": "highest"
          }
        }
      ],
      "constraints": [
        "must ship in 20 minutes",
        "safety > throughput",
        "explicitly mark evidence gaps",
        "single response"
      ]
    }
  ]
}
